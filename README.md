# 🧪 MixUp_훈제오리구이 : Grammar Error Correction Promptathon 

본 레포지토리는 Grammar Error Correction Promptathon  실험을 재현하고 확장하기 위한 코드 및 가이드를 제공합니다.

**단, 반드시 평가 코드는 제외후 제출합니다**

## 📌 프로젝트 개요

* **목표**: ex. Solar Pro API를 활용하여 프롬프트 만으로 한국어 맞춤법 교정 성능을 개선한다. 
* **접근 전략**:
 한국어는 조사와 어미가 자유롭게 붙는 교착어로, 문맥에 따라 띄어쓰기나 문법 규칙이 달라지고 예외도 많아 일관된 규칙을 적용하기 어렵다. 따라서, 고정된 rule-based 프롬프트만으로는 다양한 경우의 수를 가진 한국어 문장들을 효과적으로 교정하기 어렵다고 판단했다.
 이에 우리는 한국어 문법의 불규칙성과 예외성, 문체의 다양성을 반영할 수 있는 전략으로 **few-shot 예시 + rule-based 중심 접근**을 선택했다. 다양한 오류 유형이 섞인 실제 사용자 문장을 예시로 제시함으로써, 모델이 정해진 규칙이 아니라 자연스러운 교정 과정 자체를 학습하게끔 유도했다. 또한 교정 과정에서 의미를 바꾸지 않고 최소한으로 수정하는 원칙을 유지하며 불필요한 윤문이나 설명이 들어가지 않도록 프롬프트를 정교화했다.

---

* **주요 실험 내용**:

| 접근 방식                  | 실험 내용 및 특징 | 결과 요약 |
|---------------------------|------------------|------------|
| **✅ Few-shot + Rule-based** | - 명확한 문법은 rule로, 예외적 문법은 예시로 처리<br>- 다양한 오류 유형 포함한 사용자 예시 활용<br>- 프롬프트 상단에 역할, 형식, 규칙 명시 | 예시와 규칙이 조화를 이루며 가장 높은 일관성과 성능을 보임 |
| **Zero-shot**              | - 단순 지시문 기반 교정 ("맞춤법 고쳐줘") | 의미가 어색해지는 경우가 많아 안정적인 교정이 어려웠음 |
| **Rule-based (단독)**       | - 띄어쓰기, 조사, 외래어 등 문법 규칙을 템플릿에 적용 | 규칙 적용은 잘 되지만 예외 문법과 문맥 판단에 취약했음 |
| **Chain-of-Thought / Feedback Loop** | - 단계적 추론(CoT), 멀티턴 수정 기반 교정 | 단문 교정에는 비효율적이고 과잉 수정이 발생했음 |

**✅ [최종 선택한 방식: Few-shot + Rule-based ]**

- Few-shot + Rule-based 방식
    
    기존의 rule-based 방식은 모델이 명확한 한국어 문법을 학습하게 하는데에는 효과적이었지만, 예외적이거나 애매한 문법 항목은 잘 처리하지 못하는 한계가 있었다.  따라서 우리는 다양한 문법들을 few-shot 예시로 제시함으로써, 모델의 일반화 성능을 향상시키고자 하였다.
    
    실험 결과, 다양한 오류 유형이 포함된 예시를 통해 LLM이 교정 패턴 자체를 학습하는 방식이 가장 효과적이었다. 특히, rule-based 규칙과 오류 문장–정답 문장 형태의 few-shot 예시를 함께 제시한 프롬프트가 가장 높은 성능을 보였다.
    
    예시를 통해 프롬프트 상단에 역할, 형식, 핵심 규칙을 명시함으로써 불필요한 운문 없이 원문의 의미를 보존하며 일관된 교정이 가능했다. 
    
    예외와 복잡한 문법이 많은 한국어에서는 핵심적인 교정 원칙과 실제 예시를 함께 보여주는 것이 더 효과적이었다.
    

**[선택하지 않은 방식: zero-shot, rule-based, Chain-of_Thought, Feedback Loop]**

- Zero-shot 방식
    
     처음에는 "맞춤법 고쳐줘" 같은 간단한 지시로 문법 교정을 시도했지만, 결과가 만족스럽지 않았다. LLM이 명확한 기준 없이 임의로 수정하면서 오히려 의미가 어색해지는 경우가 많았다. 예외가 많은 한국어 특성 상, 구체적인 기준 없이는 LLM이 제대로 작동하기 어렵다는 점을 확인했다.
    
- Rule-based 방식
    
    Template에 맞춤법, 띄어쓰기, 조사와 어미, 문장 부호, 표준어 표현, 숫자 및 외래어 등 다양한 문법 규칙을 일일이 rule로 지정해 적용해봤다. 그러나 방대한 한국어 문법 특성상, 모델이 일관성을 유지하지 못하고 혼란스러운 결과를 보이는 경우가 많았다. 명확한 규칙이 있는 문법 항목은 비교적 잘 교정했지만, 예외 조항처럼 애매하거나 문맥 의존적인 규칙들은 한계가 드러났다. 결국 이 방식은 새로운 유형의 오류에 유연하게 대응하기 어렵고, 더 적응력 있는 방식이 필요하다는 판단을 내리게 되었다.
    
- Chain-of-Thought (CoT), Feedback loop 방식
    
    Feedback loop방식은 여러 턴에 걸쳐 수정하는 방식은 수정 기준이 명확하지 않고, 이미 고친 부분을 다시 수정하거나 과잉 수정하는 등  비효율적인 결과를 보였다. 1개 문장 단위에서 완료되는 문장 교정 작업 특성을 고려하면, 여러 단계를 거치는 멀티턴 방식은 적합하지 않다고 판단하였다. CoT의 경우, 추론과정을 단계적으로 분해하는데 효과적이지만 문장 교정처럼 즉각적인 패턴 인식 및 변환 작업에는 적합하지 않았다.


[하이퍼파라미터 설정]

실험 과정에서 여러 하이퍼파라미터를 조정하며 테스트를 진행하였고,
최종적으로 다음과 같은 설정값을 선택하였다:

- temperature: 0.1
- top-p: 1.0

또한, 모델의 일반화 성능을 평가하기 위해 random_seed는 고정하지 않고 여러 값을 변경해가며 성능을 측정하였다.

---

## ⚙️ 환경 세팅 & 실행 방법

### 1. 사전 준비 

```bash
git clone https://github.com/sally7788/Mixup_dataton.git
cd Mixup_dataton/experiment
```

### 라이브러리 설치

```bash
pip install -r requirements.txt
```

### 실험 실행

```bash
python run_experiment.py --input sample_input.txt --output result.json
```

> 📎 실행 옵션 (예시):
> `--input`: 실험 대상 파일
> `--output`: 결과 저장 파일 경로

---


## 🚧 실험의 한계 및 향후 개선

* **한계**:

  * 복합 명사 및 합성어 띄어쓰기 구분 미흡

    * 예: 생각보다 → 생각 보다 (X)

    * 사전에 등재된 합성어와 의미 단위로 띄어야 하는 형식적 결합어를 구분하지 못하는 문제

  * 종결 어미 및 문장 부호 구분 부족

    * 예: ~아니야 vs ~아니니? / 진짜야? vs 진짜야.

    * 문장 어조(서술/의문/청유/명령)에 따라 적절한 종결 표현을 선택하지 못하는 문제


* **향후 개선 방향**:

  * 합성어/복합 명사 관련 사전 학습 또는 의미 기반 Few-shot 예시 추가
  * 문장 어조별 종결 표현 Few-shot 예시 보강

---

## 📂 폴더 구조

```
📁 code/
├── main.py              # 메인 실행 파일
├── config.py            # 설정 파일
├── requirements.txt     # 필요한 패키지 목록
├── __init__.py         # 패키지 초기화 파일
├── utils/              # 유틸리티 함수들
│   ├── __init__.py     # utils 패키지 초기화
│   ├── experiment.py   # 실험 실행 및 API 호출
│   └── metrics.py      # 평가 지표 계산
└── prompts/            # 프롬프트 템플릿 저장
    ├── __init__.py     # prompts 패키지 초기화
    └── templates.py    # 프롬프트 템플릿 정의
```
